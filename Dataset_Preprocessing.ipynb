{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e246196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "------------------------------------ALL Folders------------------------------------\n",
      "['20150401_Tables_de_Reference', '20150401_Tables_supports_antennes_emetteurs_bandes', '20150501_Tables_de_Reference', '20150501_Tables_supports_antennes_emetteurs_bandes', '20150602_DATA', '20150602_Tables_de_reference', '20150701_DATA', '20150701_Tables_de_reference', '20150801_DATA', '20150801_Tables_de_reference', '20150829_DATA', '20150829_Tables_de_reference', '20150926_DATA', '20150926_Tables_de_reference', '20151031_DATA', '20151031_Tables_de_reference', '20151128_DATA', '20151128_Tables_de_reference', '20160109_DATA', '20160109_Tables_de_reference', '20160130_DATA', '20160130_Tables_de_reference', '20160227_DATA', '20160227_Tables_de_reference', '20160402_DATA', '20160402_Tables_de_reference', '20160430_DATA', '20160430_Tables_de_reference', '20160528_DATA', '20160528_Tables_de_reference', '20160630_DATA', '20160702_Tables_de_reference', '20160730_DATA2', '20160730_Tables_de_reference', '20160827_DATA', '20160827_Tables_de_reference', '20160930_DATA', '20160930_Tables_de_reference', '20161028_DATA', '20161028_Tables_de_reference', '20161126_DATA', '20161126_Tables_de_reference', '20161224_DATA', '20161224_Tables_de_reference (copy)', '20170128_DATA', '20170128_Tables_de_reference', '20170225_DATA', '20170225_Tables_de_reference', '20170401_DATA', '20170401_Tables_de_reference', '20170429_DATA', '20170429_Tables_de_reference', '20170531_DATA', '20170531_Tables_de_reference', '20170701_DATA', '20170701_Tables_de_reference', '20170729_DATA', '20170729_Tables_de_reference', '20170831_DATA', '20170831_Tables_de_reference', '20170930_Tables_de_reference', '20171005_DATA', '20171031_DATA', '20171031_Tables_de_reference', '20171130_DATA', '20171130_Tables_de_reference', '20171222_Export_Etalab_Data', '20171222_Export_Etalab_Ref', '20180131_DATA', '20180131_Tables_de_reference', '20180228_Export_Etalab_Data', '20180228_Export_Etalab_Ref', '20180330_Export_Etalab_Data', '20180330_Export_Etalab_Ref', '20180427_Export_Etalab_Data', '20180427_Export_Etalab_Ref', '20180531_Export_Etalab_Data', '20180531_Export_Etalab_Ref', '20180629_Export_Etalab_Data', '20180629_Export_Etalab_Ref', '20180801_Export_Etalab_Data', '20180801_Export_Etalab_Ref', '20180831-export-etalab', '20180831-export-etalab-ref', '20180930-export-etalab-data', '20180930-export-etalab-ref', '20181031-export-etalab-data', '20181031-export-etalab-ref', '20181130-export-etalab-data', '20181130-export-etalab-ref', '20181231-export-etalab-data', '20181231-export-etalab-ref', '20190131-export-etalab-data', '20190131-export-etalab-ref', '20190228-export-etalab-data', '20190228-export-etalab-ref', '20190331-export-etalab-data', '20190331-export-etalab-ref', '20190430-export-etalab-data', '20190430-export-etalab-ref', '20190529-export-etalab-data', '20190529-export-etalab-ref', '20190628-export-etalab-data', '20190628-export-etalab-ref', '20190801-export-etalab-data', '20190801-export-etalab-ref', '20190830-export-etalab-data', '20190830-export-etalab-ref', '20191001-export-etalab-data', '20191001-export-etalab-ref', '20191031-export-etalab-data', '20191031-export-etalab-ref', '20191129-export-etalab-data', '20191129-export-etalab-ref', '20200131-export-etalab-data', '20200131-export-etalab-ref', '20200430-export-etalab-data', '20200430-export-etalab-ref', '20200529-export-etalab-data', '20200529-export-etalab-ref', '20200630-export-etalab-data', '20200630-export-etalab-ref', '20200731-export-etalab-data', '20200731-export-etalab-ref', '20200831-export-etalab-data', '20200831-export-etalab-ref', '20200930-export-etalab-data', '20200930-export-etalab-ref', '20201030-export-etalab-data', '20201030-export-etalab-ref', '20201201-export-etalab-data', '20201201-export-etalab-ref', '20210107-export-etalab', '20210107-export-etalab-ref', '20210129-export-etalab-data', '20210129-export-etalab-ref', '20210226-export-etalab-data', '20210226-export-etalab-ref', '20210331-export-etalab-data', '20210331-export-etalab-ref', '20210503-export-etalab-data', '20210503-export-etalab-ref', '20210531-export-etalab-data', '20210531-export-etalab-ref', '20210630-export-etalab-data', '20210630-export-etalab-ref', '20210801-export-etalab-data', '20210801-export-etalab-ref', '20210831-export-etalab-ref', '20210930-export-etalab-data', '20210930-export-etalab-ref', '20211029-export-etalab-data', '20211029-export-etalab-ref', '20211130-export-etalab-data', '20211130-export-etalab-ref', '20211223-export-etalab-data', '20211223-export-etalab-ref', '20220131-export-etalab-data', '20220131-export-etalab-ref', '20220228-export-etalab-data', '20220228-export-etalab-ref', '20220331-export-etalab-data', '20220331-export-etalab-ref', '20220429-export-etalab-data', '20220429-export-etalab-ref', '20220531-export-etalab-data', '20220531-export-etalab-ref', '20220630-export-etalab-data', '20220630-export-etalab-ref', '20220729-export-etalab-data', '20220729-export-etalab-ref', '20220831-export-etalab-data', '20220831-export-etalab-ref', '20220930-export-etalab-data', '20220930-export-etalab-ref', 'table-de-reference-mars-2020', 'tables-de-reference-avril-2020', 'tables-de-reference-janvier-2020', 'tables-supports-antennes-emetteurs-bandes-avril-2020', 'tables-supports-antennes-emetteurs-bandes-janvier-2020', 'tables-supports-antennes-emetteurs-bandes-mars-2020']\n",
      "------------------------------------Data Folders------------------------------------\n",
      "['20150401_Tables_supports_antennes_emetteurs_bandes', '20150501_Tables_supports_antennes_emetteurs_bandes', '20150602_DATA', '20150701_DATA', '20150801_DATA', '20150829_DATA', '20150926_DATA', '20151031_DATA', '20151128_DATA', '20160109_DATA', '20160130_DATA', '20160227_DATA', '20160402_DATA', '20160430_DATA', '20160528_DATA', '20160630_DATA', '20160730_DATA2', '20160827_DATA', '20160930_DATA', '20161028_DATA', '20161126_DATA', '20161224_DATA', '20170128_DATA', '20170225_DATA', '20170401_DATA', '20170429_DATA', '20170531_DATA', '20170701_DATA', '20170729_DATA', '20170831_DATA', '20171005_DATA', '20171031_DATA', '20171130_DATA', '20171222_Export_Etalab_Data', '20180131_DATA', '20180228_Export_Etalab_Data', '20180330_Export_Etalab_Data', '20180427_Export_Etalab_Data', '20180531_Export_Etalab_Data', '20180629_Export_Etalab_Data', '20180801_Export_Etalab_Data', '20180831-export-etalab', '20180930-export-etalab-data', '20181031-export-etalab-data', '20181130-export-etalab-data', '20181231-export-etalab-data', '20190131-export-etalab-data', '20190228-export-etalab-data', '20190331-export-etalab-data', '20190430-export-etalab-data', '20190529-export-etalab-data', '20190628-export-etalab-data', '20190801-export-etalab-data', '20190830-export-etalab-data', '20191001-export-etalab-data', '20191031-export-etalab-data', '20191129-export-etalab-data', '20200131-export-etalab-data', '20200430-export-etalab-data', '20200529-export-etalab-data', '20200630-export-etalab-data', '20200731-export-etalab-data', '20200831-export-etalab-data', '20200930-export-etalab-data', '20201030-export-etalab-data', '20201201-export-etalab-data', '20210107-export-etalab', '20210129-export-etalab-data', '20210226-export-etalab-data', '20210331-export-etalab-data', '20210503-export-etalab-data', '20210531-export-etalab-data', '20210630-export-etalab-data', '20210801-export-etalab-data', '20210930-export-etalab-data', '20211029-export-etalab-data', '20211130-export-etalab-data', '20211223-export-etalab-data', '20220131-export-etalab-data', '20220228-export-etalab-data', '20220331-export-etalab-data', '20220429-export-etalab-data', '20220531-export-etalab-data', '20220630-export-etalab-data', '20220729-export-etalab-data', '20220831-export-etalab-data', '20220930-export-etalab-data', 'tables-supports-antennes-emetteurs-bandes-avril-2020', 'tables-supports-antennes-emetteurs-bandes-janvier-2020', 'tables-supports-antennes-emetteurs-bandes-mars-2020']\n",
      "------------------------------------Reference Folders------------------------------------\n",
      "['20150401_Tables_de_Reference', '20150501_Tables_de_Reference', '20150602_Tables_de_reference', '20150701_Tables_de_reference', '20150801_Tables_de_reference', '20150829_Tables_de_reference', '20150926_Tables_de_reference', '20151031_Tables_de_reference', '20151128_Tables_de_reference', '20160109_Tables_de_reference', '20160130_Tables_de_reference', '20160227_Tables_de_reference', '20160402_Tables_de_reference', '20160430_Tables_de_reference', '20160528_Tables_de_reference', '20160702_Tables_de_reference', '20160730_Tables_de_reference', '20160827_Tables_de_reference', '20160930_Tables_de_reference', '20161028_Tables_de_reference', '20161126_Tables_de_reference', '20161224_Tables_de_reference (copy)', '20170128_Tables_de_reference', '20170225_Tables_de_reference', '20170401_Tables_de_reference', '20170429_Tables_de_reference', '20170531_Tables_de_reference', '20170701_Tables_de_reference', '20170729_Tables_de_reference', '20170831_Tables_de_reference', '20170930_Tables_de_reference', '20171031_Tables_de_reference', '20171130_Tables_de_reference', '20171222_Export_Etalab_Ref', '20180131_Tables_de_reference', '20180228_Export_Etalab_Ref', '20180330_Export_Etalab_Ref', '20180427_Export_Etalab_Ref', '20180531_Export_Etalab_Ref', '20180629_Export_Etalab_Ref', '20180801_Export_Etalab_Ref', '20180831-export-etalab-ref', '20180930-export-etalab-ref', '20181031-export-etalab-ref', '20181130-export-etalab-ref', '20181231-export-etalab-ref', '20190131-export-etalab-ref', '20190228-export-etalab-ref', '20190331-export-etalab-ref', '20190430-export-etalab-ref', '20190529-export-etalab-ref', '20190628-export-etalab-ref', '20190801-export-etalab-ref', '20190830-export-etalab-ref', '20191001-export-etalab-ref', '20191031-export-etalab-ref', '20191129-export-etalab-ref', '20200131-export-etalab-ref', '20200430-export-etalab-ref', '20200529-export-etalab-ref', '20200630-export-etalab-ref', '20200731-export-etalab-ref', '20200831-export-etalab-ref', '20200930-export-etalab-ref', '20201030-export-etalab-ref', '20201201-export-etalab-ref', '20210107-export-etalab-ref', '20210129-export-etalab-ref', '20210226-export-etalab-ref', '20210331-export-etalab-ref', '20210503-export-etalab-ref', '20210531-export-etalab-ref', '20210630-export-etalab-ref', '20210801-export-etalab-ref', '20210831-export-etalab-ref', '20210930-export-etalab-ref', '20211029-export-etalab-ref', '20211130-export-etalab-ref', '20211223-export-etalab-ref', '20220131-export-etalab-ref', '20220228-export-etalab-ref', '20220331-export-etalab-ref', '20220429-export-etalab-ref', '20220531-export-etalab-ref', '20220630-export-etalab-ref', '20220729-export-etalab-ref', '20220831-export-etalab-ref', '20220930-export-etalab-ref', 'table-de-reference-mars-2020', 'tables-de-reference-avril-2020', 'tables-de-reference-janvier-2020']\n",
      "------------------------------------Dates already Processed------------------------------------\n",
      "['20150401', '20150501', '20150602', '20150701', '20150801', '20150829', '20150926', '20151031', '20151128', '20160109', '20160130', '20160227', '20160402', '20160430', '20160528', '20160630', '20160730', '20160827', '20160930', '20161028', '20161126', '20161224', '20170128', '20170225', '20170401', '20170429', '20170531', '20170701', '20170729', '20170831', '20171005', '20171031', '20171130', '20171222', '20180131', '20180228', '20180330', '20180427', '20180531', '20180629', '20180801', '20180831', '20180930', '20181031', '20181130', '20181231', '20190131', '20190228', '20190331', '20190430', '20190529', '20190628', '20190801', '20190830', '20191001', '20191031', '20191129', '20200101', '20200131', '20200301', '20200401', '20200430', '20200529', '20200630', '20200731', '20200831', '20200930', '20201030', '20201201', '20210107', '20210129', '20210226', '20210331', '20210503', '20210531', '20210630', '20210801', '20210930', '20211029', '20211130', '20211223', '20220131', '20220228', '20220331', '20220429', '20220531', '20220630', '20220729', '20220831', 'NUM_STATIONS']\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "database_dir = './ANFR Dataset'              #It should be made sure that there are equal number of data and ref folders here\n",
    "\n",
    "pre_processed_dir = './Pre-processed data'\n",
    "\n",
    "#------------The main data directory contains data and ref folder for each month's data------------#\n",
    "folders_in_data_dir = [folder for folder in listdir(database_dir) if isdir(join(database_dir, folder))]\n",
    "data_tables_folder = [folder for folder in folders_in_data_dir if ((\"ref\" not in folder) and (\"Ref\" not in folder))]\n",
    "reference_folder = [folder for folder in folders_in_data_dir if ((\"ref\" in folder) or (\"Ref\" in folder))]\n",
    "\n",
    "already_processed = [file.split('.')[0] for file in listdir(pre_processed_dir) if isfile(join(pre_processed_dir, file))]\n",
    "\n",
    "print(\"------------------------------------ALL Folders------------------------------------\")\n",
    "print(folders_in_data_dir)\n",
    "\n",
    "print(\"------------------------------------Data Folders------------------------------------\")\n",
    "print(data_tables_folder)\n",
    "\n",
    "print(\"------------------------------------Reference Folders------------------------------------\")\n",
    "print(reference_folder)\n",
    "\n",
    "print(\"------------------------------------Dates already Processed------------------------------------\")\n",
    "print(already_processed)\n",
    "\n",
    "total_num_bs_df = pd.DataFrame(columns=['Dates', 'Total_NUM_BSs'])         #We will save this in a file at the end. For comparison with the number of stations of the 4 main operators.\n",
    "if 'NUM_STATIONS' in already_processed:\n",
    "    total_num_bs_df = pd.read_csv(join(pre_processed_dir, 'NUM_STATIONS.txt'), sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05413ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Dates----------------------\n",
      "['20150401', '20150501', '20150602', '20150701', '20150801', '20150829', '20150926', '20151031', '20151128', '20160109', '20160130', '20160227', '20160402', '20160430', '20160528', '20160630', '20160730', '20160827', '20160930', '20161028', '20161126', '20161224', '20170128', '20170225', '20170401', '20170429', '20170531', '20170701', '20170729', '20170831', '20171005', '20171031', '20171130', '20171222', '20180131', '20180228', '20180330', '20180427', '20180531', '20180629', '20180801', '20180831', '20180930', '20181031', '20181130', '20181231', '20190131', '20190228', '20190331', '20190430', '20190529', '20190628', '20190801', '20190830', '20191001', '20191031', '20191129', '20200131', '20200430', '20200529', '20200630', '20200731', '20200831', '20200930', '20201030', '20201201', '20210107', '20210129', '20210226', '20210331', '20210503', '20210531', '20210630', '20210801', '20210930', '20211029', '20211130', '20211223', '20220131', '20220228', '20220331', '20220429', '20220531', '20220630', '20220729', '20220831', '20220930', '20200401', '20200101', '20200301']\n",
      "----------------------Mapped Folders (In a list one after the another)----------------------\n",
      "['20150401_Tables_supports_antennes_emetteurs_bandes', '20150401_Tables_de_Reference', '20150501_Tables_supports_antennes_emetteurs_bandes', '20150501_Tables_de_Reference', '20150602_DATA', '20150602_Tables_de_reference', '20150701_DATA', '20150701_Tables_de_reference', '20150801_DATA', '20150801_Tables_de_reference', '20150829_DATA', '20150829_Tables_de_reference', '20150926_DATA', '20150926_Tables_de_reference', '20151031_DATA', '20151031_Tables_de_reference', '20151128_DATA', '20151128_Tables_de_reference', '20160109_DATA', '20160109_Tables_de_reference', '20160130_DATA', '20160130_Tables_de_reference', '20160227_DATA', '20160227_Tables_de_reference', '20160402_DATA', '20160402_Tables_de_reference', '20160430_DATA', '20160430_Tables_de_reference', '20160528_DATA', '20160528_Tables_de_reference', '20160630_DATA', '20160702_Tables_de_reference', '20160730_DATA2', '20160730_Tables_de_reference', '20160827_DATA', '20160827_Tables_de_reference', '20160930_DATA', '20160930_Tables_de_reference', '20161028_DATA', '20161028_Tables_de_reference', '20161126_DATA', '20161126_Tables_de_reference', '20161224_DATA', '20161224_Tables_de_reference (copy)', '20170128_DATA', '20170128_Tables_de_reference', '20170225_DATA', '20170225_Tables_de_reference', '20170401_DATA', '20170401_Tables_de_reference', '20170429_DATA', '20170429_Tables_de_reference', '20170531_DATA', '20170531_Tables_de_reference', '20170701_DATA', '20170701_Tables_de_reference', '20170729_DATA', '20170729_Tables_de_reference', '20170831_DATA', '20170831_Tables_de_reference', '20171005_DATA', '20170930_Tables_de_reference', '20171031_DATA', '20171031_Tables_de_reference', '20171130_DATA', '20171130_Tables_de_reference', '20171222_Export_Etalab_Data', '20171222_Export_Etalab_Ref', '20180131_DATA', '20180131_Tables_de_reference', '20180228_Export_Etalab_Data', '20180228_Export_Etalab_Ref', '20180330_Export_Etalab_Data', '20180330_Export_Etalab_Ref', '20180427_Export_Etalab_Data', '20180427_Export_Etalab_Ref', '20180531_Export_Etalab_Data', '20180531_Export_Etalab_Ref', '20180629_Export_Etalab_Data', '20180629_Export_Etalab_Ref', '20180801_Export_Etalab_Data', '20180801_Export_Etalab_Ref', '20180831-export-etalab', '20180831-export-etalab-ref', '20180930-export-etalab-data', '20180930-export-etalab-ref', '20181031-export-etalab-data', '20181031-export-etalab-ref', '20181130-export-etalab-data', '20181130-export-etalab-ref', '20181231-export-etalab-data', '20181231-export-etalab-ref', '20190131-export-etalab-data', '20190131-export-etalab-ref', '20190228-export-etalab-data', '20190228-export-etalab-ref', '20190331-export-etalab-data', '20190331-export-etalab-ref', '20190430-export-etalab-data', '20190430-export-etalab-ref', '20190529-export-etalab-data', '20190529-export-etalab-ref', '20190628-export-etalab-data', '20190628-export-etalab-ref', '20190801-export-etalab-data', '20190801-export-etalab-ref', '20190830-export-etalab-data', '20190830-export-etalab-ref', '20191001-export-etalab-data', '20191001-export-etalab-ref', '20191031-export-etalab-data', '20191031-export-etalab-ref', '20191129-export-etalab-data', '20191129-export-etalab-ref', '20200131-export-etalab-data', '20200131-export-etalab-ref', '20200430-export-etalab-data', '20200430-export-etalab-ref', '20200529-export-etalab-data', '20200529-export-etalab-ref', '20200630-export-etalab-data', '20200630-export-etalab-ref', '20200731-export-etalab-data', '20200731-export-etalab-ref', '20200831-export-etalab-data', '20200831-export-etalab-ref', '20200930-export-etalab-data', '20200930-export-etalab-ref', '20201030-export-etalab-data', '20201030-export-etalab-ref', '20201201-export-etalab-data', '20201201-export-etalab-ref', '20210107-export-etalab', '20210107-export-etalab-ref', '20210129-export-etalab-data', '20210129-export-etalab-ref', '20210226-export-etalab-data', '20210226-export-etalab-ref', '20210331-export-etalab-data', '20210331-export-etalab-ref', '20210503-export-etalab-data', '20210503-export-etalab-ref', '20210531-export-etalab-data', '20210531-export-etalab-ref', '20210630-export-etalab-data', '20210630-export-etalab-ref', '20210801-export-etalab-data', '20210801-export-etalab-ref', '20210930-export-etalab-data', '20210930-export-etalab-ref', '20211029-export-etalab-data', '20211029-export-etalab-ref', '20211130-export-etalab-data', '20211130-export-etalab-ref', '20211223-export-etalab-data', '20211223-export-etalab-ref', '20220131-export-etalab-data', '20220131-export-etalab-ref', '20220228-export-etalab-data', '20220228-export-etalab-ref', '20220331-export-etalab-data', '20220331-export-etalab-ref', '20220429-export-etalab-data', '20220429-export-etalab-ref', '20220531-export-etalab-data', '20220531-export-etalab-ref', '20220630-export-etalab-data', '20220630-export-etalab-ref', '20220729-export-etalab-data', '20220729-export-etalab-ref', '20220831-export-etalab-data', '20220831-export-etalab-ref', '20220930-export-etalab-data', '20220930-export-etalab-ref', 'tables-supports-antennes-emetteurs-bandes-avril-2020', 'tables-de-reference-avril-2020', 'tables-supports-antennes-emetteurs-bandes-janvier-2020', 'tables-de-reference-janvier-2020', 'tables-supports-antennes-emetteurs-bandes-mars-2020', 'table-de-reference-mars-2020']\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------Finding the mapping between the data and the ref folders---------------------------------#\n",
    "dates = []\n",
    "mapped_folders = []       #This list will contain each data and ref folder name in sequence. First data then ref for the same month and then so on.\n",
    "\n",
    "months = ['janvier', 'février', 'mars', 'avril', 'mai', 'juin', 'juillet', 'aout', 'septembre', 'octobre', 'novembre', 'décembre']\n",
    "\n",
    "for current_data_folder in data_tables_folder:\n",
    "    mapped_folders.append(current_data_folder)\n",
    "    \n",
    "    data_date = ''\n",
    "    #---------if data folder is named in this format -->'tables-supports-antennes-emetteurs-bandes-janvier-2020'---------#\n",
    "    for month in months:\n",
    "        if month in current_data_folder:\n",
    "            month_number = months.index(month) + 1\n",
    "            if month_number < 10:\n",
    "                month_number = '0' + str(month_number)\n",
    "            year = current_data_folder.split('-')[6]\n",
    "            day = '01'\n",
    "            data_date = year + month_number + day\n",
    "    #---------if data folder is named in this format -->'20211029-export-etalab-data'---------Doesn't matter if there is no data in the name#\n",
    "    if data_date == '':   \n",
    "        if len(current_data_folder.split('-')) > 1:\n",
    "            data_date = current_data_folder.split('-')[0]\n",
    "        else:\n",
    "            data_date = current_data_folder.split('_')[0]    #Some folders use underscore instead of dash\n",
    "    dates.append(data_date)\n",
    "    \n",
    "    for current_ref_folder in reference_folder:\n",
    "        ref_date = ''\n",
    "        #---------if ref folder is named in this format -->'table-de-reference-mars-2020'---------#\n",
    "        for month in months:\n",
    "            if month in current_ref_folder:\n",
    "                month_number = months.index(month) + 1\n",
    "                if month_number < 10:\n",
    "                    month_number = '0' + str(month_number)\n",
    "                year = current_ref_folder.split('-')[4]\n",
    "                day = '01'\n",
    "                ref_date = year + month_number + day\n",
    "        #---------if data folder is named in this format -->'20210801-export-etalab-ref'---------#\n",
    "        if ref_date == '':\n",
    "            if len(current_ref_folder.split('-')) > 1:\n",
    "                ref_date = current_ref_folder.split('-')[0]\n",
    "            else:\n",
    "                ref_date = current_ref_folder.split('_')[0]    #Some folders use underscore instead of dash\n",
    "        \n",
    "        date_diff = abs(datetime.strptime(data_date, '%Y%m%d') - datetime.strptime(ref_date, '%Y%m%d'))\n",
    "        \n",
    "        if date_diff < timedelta(days = 7):     #Assuming that the difference between the upload of data and ref folders won't be more than 5 days. Less than 5 days mean they belong to the same set. Also assuming that different months data is uploade after atleast 5 days\n",
    "            mapped_folders.append(current_ref_folder)\n",
    "            break\n",
    "\n",
    "print(\"----------------------Dates----------------------\")\n",
    "print(dates)\n",
    "\n",
    "print(\"----------------------Mapped Folders (In a list one after the another)----------------------\")\n",
    "print(mapped_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92911a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods for using below: For adding the FDD BW and TDD BW columns in the dataframe.\n",
    "def add_FDD_BW_col(row):\n",
    "    if row['DUPLEX_TYPE'] == 'F' or row['DUPLEX_TYPE'] == 'T&F':\n",
    "        return row['BW']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def add_TDD_BW_col(row):\n",
    "    if row['DUPLEX_TYPE'] == 'T' or row['DUPLEX_TYPE'] == 'T&F':\n",
    "        return row['BW']\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19739f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently Pre-Processing\n",
      "./ANFR Dataset\\20220930-export-etalab-data\n",
      "./ANFR Dataset\\20220930-export-etalab-ref\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "encoding_type = 'latin1'              #This type of encoding is well adapted for Western European languages.\n",
    "\n",
    "for i in range(0, len(mapped_folders), 2):\n",
    "    data_path = join(database_dir, mapped_folders[i])\n",
    "    reference_path = join(database_dir, mapped_folders[i + 1])\n",
    "    \n",
    "    data_date = dates[i//2]\n",
    "    \n",
    "    if data_date in already_processed:\n",
    "        continue\n",
    "    \n",
    "    print(\"Currently Pre-Processing\")\n",
    "    print(data_path)\n",
    "    print(reference_path)\n",
    "    \n",
    "    #-----------------Converting reference files to dataframes - will be used to find mapping in the data files-----------------#\n",
    "    operators_df = pd.read_csv(join(reference_path, 'SUP_EXPLOITANT.txt'), sep = ';', dtype=str, encoding=encoding_type, on_bad_lines='skip')       #Not entirely sure why but this encoding type works for all. On_bad_lines for ID 244 -->skipping it.\n",
    "    antenna_type_df = pd.read_csv(join(reference_path, 'SUP_TYPE_ANTENNE.txt'), sep = ';', dtype=str, encoding=encoding_type)\n",
    "    #-----------------Creating dictionaries from the reference dataframes-----------------#\n",
    "    operators_mapping = operators_df.set_index('ADM_ID').T.to_dict('index')\n",
    "    operators_mapping = operators_mapping['ADM_LB_NOM']                    #The actual dictionary is a nested dictionary  \n",
    "    \n",
    "    antenna_type_mapping = antenna_type_df.set_index('TAE_ID').T.to_dict('index')\n",
    "    antenna_type_mapping = antenna_type_mapping['TAE_LB']                  #The actual dictionary is a nested dictionary\n",
    "    \n",
    "    #-----------------Reading actual datafiles as panda dataframes-----------------#   \n",
    "    station_df = pd.read_csv(join(data_path, 'SUP_STATION.txt'), sep = ';', dtype=str, encoding=encoding_type)\n",
    "    \n",
    "    #In earlier files this header is not capitalized so we need to check and get it so that we can extract this col if needed\n",
    "    service_date_col_name = ''\n",
    "    col_names_in_station_df = station_df.columns\n",
    "    for col_name in col_names_in_station_df:\n",
    "            if 'dte_en_service' in col_name.lower():\n",
    "                service_date_col_name = col_name\n",
    "                \n",
    "    station_df = station_df[['STA_NM_ANFR','ADM_ID', service_date_col_name]]                                                   #Selecting all the stations assuming all are in service\n",
    "    #In some earlier data files, in the ADM_ID column there are commas in the data file but not in the reference file so we need to take care of this\n",
    "    station_df['ADM_ID'] = station_df['ADM_ID'].str.split(',').str.get(0)\n",
    "    #----------------------Replacing the values in the data columns using the reference----------------------#\n",
    "    station_df['ADM_ID'] = station_df['ADM_ID'].map(operators_mapping)\n",
    "    \n",
    "    antenna_df = pd.read_csv(join(data_path, 'SUP_ANTENNE.txt'), sep = ';', dtype=str, encoding=encoding_type)\n",
    "    antenna_df = antenna_df[['STA_NM_ANFR', 'AER_ID', 'TAE_ID']]\n",
    "    #----------------------Replacing the values in the data columns using the reference----------------------#\n",
    "    antenna_df['TAE_ID'] = antenna_df['TAE_ID'].map(antenna_type_mapping)\n",
    "\n",
    "    transmitter_df = pd.read_csv(join(data_path, 'SUP_EMETTEUR.txt'), sep = ';', dtype=str, encoding=encoding_type)\n",
    "    \n",
    "    transmitter_df = transmitter_df[['STA_NM_ANFR', 'EMR_ID', 'EMR_LB_SYSTEME', 'AER_ID']]\n",
    "    #-----------------------Only cellular systems-----------------------#\n",
    "    cellular_systems = ['GSM', 'UMTS', 'LTE', '5G']\n",
    "    transmitter_df = transmitter_df[transmitter_df['EMR_LB_SYSTEME'].str.split(' ').str[0].isin(cellular_systems)]\n",
    "    transmitter_df = transmitter_df[~transmitter_df['EMR_LB_SYSTEME'].str.contains(\" Expe\")]             #No experimential bands\n",
    "    transmitter_df = transmitter_df[~transmitter_df['EMR_LB_SYSTEME'].str.contains(\" R\")]                #No GSM R\n",
    "    transmitter_df = transmitter_df[~transmitter_df['EMR_LB_SYSTEME'].str.contains(\" P\")]                #No Private LTE\n",
    "    \n",
    "    band_df = pd.read_csv(join(data_path, 'SUP_BANDE.txt'), sep = ';', dtype=str, encoding=encoding_type)\n",
    "    band_df = band_df[['STA_NM_ANFR', 'BAN_ID', 'EMR_ID', 'BAN_NB_F_DEB', 'BAN_NB_F_FIN', 'BAN_FG_UNITE']]    \n",
    "\n",
    "    #--------------Sequential inner join operations to create one single dataframe--------------#\n",
    "    station_antenna_df = station_df.merge(antenna_df, on = ['STA_NM_ANFR'])\n",
    "    station_antenna_transmitter_df = station_antenna_df.merge(transmitter_df, on = ['AER_ID', 'STA_NM_ANFR'])\n",
    "    all_df = station_antenna_transmitter_df.merge(band_df, on = ['EMR_ID', 'STA_NM_ANFR'])\n",
    "    \n",
    "    #Dropping any rows with NaN values #Especially, where DT_EN_SERVICE is null, we are assuming that the stations are not in service.\n",
    "    all_df = all_df.dropna()\n",
    "    \n",
    "    #--------------Saving the total number of in service base stations--------------#\n",
    "    num_bs = all_df['STA_NM_ANFR'].nunique()\n",
    "    row = [data_date, num_bs]\n",
    "    total_num_bs_df.loc[-1] = row\n",
    "    total_num_bs_df =  total_num_bs_df.reset_index(drop=True)\n",
    "    \n",
    "    #-----------------------Selecting the stations only from the main cellular operators-----------------------#\n",
    "    main_operators = ['BOUYGUES TELECOM', 'ORANGE', 'SFR', 'FREE MOBILE']\n",
    "    all_df = all_df.loc[all_df['ADM_ID'].isin(main_operators)]\n",
    "    \n",
    "    #--------------Replacing comma with decimal--------------#\n",
    "    all_df['BAN_NB_F_DEB'] = all_df['BAN_NB_F_DEB'].str.replace(',','.')\n",
    "    all_df['BAN_NB_F_FIN'] = all_df['BAN_NB_F_FIN'].str.replace(',','.')\n",
    "    \n",
    "    #--------------------Removing unnecessary info from the perspective of energy consumption calculations. Also summarizing and compressing the information for faster anlysis in the next stage--------------------#   \n",
    "    all_df['BW'] = all_df['BAN_NB_F_FIN'].astype(float) - all_df['BAN_NB_F_DEB'].astype(float)\n",
    "    all_df['BW'] = all_df['BW'].round(1)\n",
    "    \n",
    "    all_df = all_df.drop(['BAN_NB_F_FIN', 'BAN_ID', 'AER_ID'], axis = 1)       #Not dropping the date column now as we require this for power calculations\n",
    "    \n",
    "    all_df = all_df.groupby(['STA_NM_ANFR', service_date_col_name, 'ADM_ID', 'TAE_ID', 'EMR_ID', 'EMR_LB_SYSTEME', 'BW', 'BAN_FG_UNITE']).nunique()              #Grouping the columns based on the specified columns --> This would return the number of unique values (per set) for the other columns which are not specified\n",
    "    \n",
    "    #-------The previous step returns --> Index ('STA_NM_ANFR', 'ADM_ID', 'TAE_ID', ' EMR_LB_SYSTEME', 'EMR_ID', 'BW') Columns ('BAN_NB_F_DEB'), the columns actually tell the number of unique values for each index\n",
    "    #In the above dataframe if there are 2 values for starting frequency it is FDD (meaning 2 bands - one for the uplink while the other for the downlink) while 1 denotes TDD. \n",
    "    #There are cases where there is a 3 in the starting frequency column. \n",
    "    #This means that the transceiver implements both TDD & FDD. (2 starting frequencies for FDD while 1 for TDD)\n",
    "    #This case will occur only for SFR in the 2.1 GHZ band because the BW for SFR (5.0MHZ) is same for TDD and FDD.\n",
    "\n",
    "    #----Hence mentioning FDD or TDD in the dataframe----#\n",
    "    all_df['BAN_NB_F_DEB'] = all_df['BAN_NB_F_DEB'].map({1 : 'T', 2 : 'F', 3:'T&F'})\n",
    "    all_df = all_df.rename(columns={'BAN_NB_F_DEB': 'DUPLEX_TYPE'})\n",
    "    \n",
    "    #-------Creating the index back into the columns-------#\n",
    "    all_df = all_df.reset_index(level=['STA_NM_ANFR', service_date_col_name, 'ADM_ID', 'TAE_ID', 'EMR_LB_SYSTEME', 'EMR_ID', 'BW', 'BAN_FG_UNITE'])\n",
    "    \n",
    "    #-------Applying the function to specify the FDD and TDD BWs with respect to each BW for each transceiver.\n",
    "    all_df['FDD_BW'] = all_df.apply(add_FDD_BW_col, axis=1)\n",
    "    all_df['TDD_BW'] = all_df.apply(add_TDD_BW_col, axis=1)\n",
    "    \n",
    "    all_df = all_df.drop(['BW', 'DUPLEX_TYPE'], axis = 1)      #dropping the columns that we don't require anymore\n",
    "    \n",
    "    #Also note that the mentioned Bandwidth for FDD is half (only transmit or receive not combined) while for TDD, the mentioned bandwidth is the whole bandwidth\n",
    "    \n",
    "    #Getting the aggregate FDD and TDD BW for each transceiver\n",
    "    all_df = all_df.groupby(['STA_NM_ANFR', service_date_col_name, 'ADM_ID', 'TAE_ID', 'EMR_ID', 'EMR_LB_SYSTEME', 'BAN_FG_UNITE'])[['FDD_BW', 'TDD_BW']].sum()\n",
    "    \n",
    "    #-------Creating the index back into the columns-------#\n",
    "    all_df = all_df.reset_index(level=['STA_NM_ANFR', service_date_col_name, 'ADM_ID', 'TAE_ID', 'EMR_ID', 'EMR_LB_SYSTEME', 'BAN_FG_UNITE'])\n",
    "    \n",
    "    #-----------------------------Renaming the headers to make them more clear-----------------------------#\n",
    "    all_df = all_df.rename(columns={'STA_NM_ANFR': 'BS_ID', service_date_col_name: 'DoS', 'ADM_ID': 'OPR_NAME', 'TAE_ID': 'ANT_TYPE', 'EMR_ID': 'TRX_ID', 'EMR_LB_SYSTEME': 'System', 'BAN_FG_UNITE': 'BW_UNIT'}) \n",
    "    all_df = all_df.reindex(columns=['BS_ID', 'DoS', 'OPR_NAME', 'ANT_TYPE', 'TRX_ID', 'System', 'FDD_BW', 'TDD_BW', 'BW_UNIT'])\n",
    "    \n",
    "    #-----------------------------Saving the dataframe to a textfile-----------------------------#\n",
    "    all_df.to_csv(join(pre_processed_dir, data_date) + '.txt', sep =';', index=False)\n",
    "    print(\"-------------------------------------------------------------\")\n",
    "    \n",
    "#----------------Writing the total num of stations to a textfile----------------#\n",
    "total_num_bs_df.to_csv(join(pre_processed_dir, 'NUM_STATIONS.txt'), sep =';', index=False, encoding=encoding_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
